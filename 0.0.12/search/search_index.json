{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"rapidstats","text":""},{"location":"bootstrap.html","title":"Bootstrap","text":""},{"location":"bootstrap.html#rapidstats._bootstrap.Bootstrap","title":"<code>Bootstrap</code>","text":"<p>Computes a two-sided bootstrap confidence interval of a statistic. The process is as follows:</p> <ol> <li>Resample 100% of the data with replacement for <code>iterations</code></li> <li>Compute the statistic on each resample</li> </ol> <p>If the method is <code>percentile</code>, we stop here and compute the interval of the bootstrap distribution that is symmetric about the median and contains <code>confidence</code> of the bootstrap statistics.</p> <p>If the method is <code>basic</code>, compute the statistic on the original data and generate the \"Reverse Percentile Interval.\"</p> <p>If the method is <code>BCa</code>,</p> <ol> <li>Compute the statistic on the original data</li> <li>Compute the statistic on the data with the ith row deleted (jacknife)</li> </ol> <p>and generate the \"Bias Corrected and Accelerated Interval.\"</p> <p>The result of each method will be a three-tuple of (lower, mean, upper).</p> <p>Parameters:</p> Name Type Description Default <code>iterations</code> <code>int</code> <p>How many times to resample the data, by default 1_000</p> <code>1000</code> <code>confidence</code> <code>float</code> <p>The confidence level, by default 0.95</p> <code>0.95</code> <code>method</code> <code>Literal[&amp;quot;percentile&amp;quot;, &amp;quot;basic&amp;quot;, &amp;quot;BCa&amp;quot;]</code> <p>Whether to return the Percentile, Basic / Reverse Percentile, or Bias Corrected and Accelerated Interval, by default \"percentile\"</p> <code>'percentile'</code> <code>seed</code> <code>Optional[int]</code> <p>Seed that controls resampling. Set this to any integer to make results reproducible, by default None</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the method is not one of <code>percentile</code>, <code>basic</code>, or <code>BCa</code></p> <p>Examples:</p> <pre><code>import rapidstats\nci = rapidstats.Bootstrap(seed=208).mean([1, 2, 3])\n</code></pre> <p>(1.0, 1.9783333333333328, 3.0)</p> Source code in <code>python/rapidstats/_bootstrap.py</code> <pre><code>class Bootstrap:\n    \"\"\"Computes a two-sided bootstrap confidence interval of a statistic. The\n    process is as follows:\n\n    1. Resample 100% of the data with replacement for `iterations`\n    2. Compute the statistic on each resample\n\n    If the method is `percentile`, we stop here and compute the interval of the\n    bootstrap distribution that is symmetric about the median and contains\n    `confidence` of the bootstrap statistics.\n\n    If the method is `basic`, compute the statistic on the original data and\n    generate the \"Reverse Percentile Interval.\"\n\n    If the method is `BCa`,\n\n    3. Compute the statistic on the original data\n    4. Compute the statistic on the data with the ith row deleted (jacknife)\n\n    and generate the \"Bias Corrected and Accelerated Interval.\"\n\n    The result of each method will be a three-tuple of (lower, mean, upper).\n\n    Parameters\n    ----------\n    iterations : int, optional\n        How many times to resample the data, by default 1_000\n    confidence : float, optional\n        The confidence level, by default 0.95\n    method : Literal[&amp;quot;percentile&amp;quot;, &amp;quot;basic&amp;quot;, &amp;quot;BCa&amp;quot;], optional\n        Whether to return the Percentile, Basic / Reverse Percentile, or\n        Bias Corrected and Accelerated Interval, by default \"percentile\"\n    seed : Optional[int], optional\n        Seed that controls resampling. Set this to any integer to make results\n        reproducible, by default None\n\n    Raises\n    ------\n    ValueError\n        If the method is not one of `percentile`, `basic`, or `BCa`\n\n    Examples\n    --------\n    ``` py\n    import rapidstats\n    ci = rapidstats.Bootstrap(seed=208).mean([1, 2, 3])\n    ```\n    (1.0, 1.9783333333333328, 3.0)\n    \"\"\"\n\n    def __init__(\n        self,\n        iterations: int = 1_000,\n        confidence: float = 0.95,\n        method: Literal[\"percentile\", \"basic\", \"BCa\"] = \"percentile\",\n        seed: Optional[int] = None,\n    ) -&gt; None:\n        if method not in (\"percentile\", \"basic\", \"BCa\"):\n            raise ValueError(\n                f\"Invalid confidence interval method `{method}`, only `percentile`, `basic`, and `BCa` are supported\",\n            )\n\n        self.iterations = iterations\n        self.confidence = confidence\n        self.seed = seed\n        self.alpha = (1 - confidence) / 2\n        self.method = method\n\n        self._params = {\n            \"iterations\": self.iterations,\n            \"alpha\": self.alpha,\n            \"method\": self.method,\n            \"seed\": self.seed,\n        }\n\n    def run(\n        self, df: pl.DataFrame, stat_func: StatFunc, **kwargs\n    ) -&gt; ConfidenceInterval:\n        default = {\"executor\": \"threads\", \"preserve_order\": False}\n        for k, v in default.items():\n            if k not in kwargs:\n                kwargs[k] = v\n\n        func = functools.partial(_bs_func, df=df, stat_func=stat_func)\n\n        if self.seed is None:\n            iterable = (None for _ in range(self.iterations))\n        else:\n            iterable = (self.seed + i for i in range(self.iterations))\n\n        bootstrap_stats = [\n            x for x in _run_concurrent(func, iterable, **kwargs) if not math.isnan(x)\n        ]\n\n        if len(bootstrap_stats) == 0:\n            return (math.nan, math.nan, math.nan)\n\n        if self.method == \"percentile\":\n            return _percentile_interval(bootstrap_stats, self.alpha)\n        elif self.method == \"basic\":\n            original_stat = stat_func(df)\n            return _basic_interval(original_stat, bootstrap_stats, self.alpha)\n        elif self.method == \"BCa\":\n            original_stat = stat_func(df)\n            jacknife_stats = _jacknife(df, stat_func)\n\n            return _bca_interval(\n                original_stat, bootstrap_stats, jacknife_stats, self.alpha\n            )\n\n    def confusion_matrix(\n        self,\n        y_true: ArrayLike,\n        y_pred: ArrayLike,\n    ) -&gt; BootstrappedConfusionMatrix:\n        df = _y_true_y_pred_to_df(y_true, y_pred)\n\n        return BootstrappedConfusionMatrix(\n            *_bootstrap_confusion_matrix(df, **self._params)\n        )\n\n    def roc_auc(self, y_true: ArrayLike, y_score: ArrayLike) -&gt; ConfidenceInterval:\n        df = _y_true_y_score_to_df(y_true, y_score)\n\n        return _bootstrap_roc_auc(df, **self._params)\n\n    def max_ks(self, y_true: ArrayLike, y_score: ArrayLike) -&gt; ConfidenceInterval:\n        df = _y_true_y_score_to_df(y_true, y_score)\n\n        return _bootstrap_max_ks(df, **self._params)\n\n    def brier_loss(self, y_true: ArrayLike, y_score: ArrayLike) -&gt; ConfidenceInterval:\n        df = _y_true_y_score_to_df(y_true, y_score)\n\n        return _bootstrap_brier_loss(df, **self._params)\n\n    def mean(self, y: ArrayLike) -&gt; ConfidenceInterval:\n        df = pl.DataFrame({\"y\": y})\n\n        return _bootstrap_mean(df, **self._params)\n\n    def adverse_impact_ratio(\n        self, y_pred: ArrayLike, protected: ArrayLike, control: ArrayLike\n    ):\n        df = pl.DataFrame(\n            {\"y_pred\": y_pred, \"protected\": protected, \"control\": control}\n        ).cast(pl.Boolean)\n\n        return _bootstrap_adverse_impact_ratio(df, **self._params)\n</code></pre>"},{"location":"bootstrap.html#rapidstats._bootstrap.BootstrappedConfusionMatrix","title":"<code>BootstrappedConfusionMatrix</code>  <code>dataclass</code>","text":"Source code in <code>python/rapidstats/_bootstrap.py</code> <pre><code>@dataclasses.dataclass\nclass BootstrappedConfusionMatrix:\n    tn: ConfidenceInterval\n    fp: ConfidenceInterval\n    fn: ConfidenceInterval\n    tp: ConfidenceInterval\n    tpr: ConfidenceInterval\n    fpr: ConfidenceInterval\n    fnr: ConfidenceInterval\n    tnr: ConfidenceInterval\n    prevalence: ConfidenceInterval\n    prevalence_threshold: ConfidenceInterval\n    informedness: ConfidenceInterval\n    precision: ConfidenceInterval\n    false_omission_rate: ConfidenceInterval\n    plr: ConfidenceInterval\n    nlr: ConfidenceInterval\n    acc: ConfidenceInterval\n    balanced_accuracy: ConfidenceInterval\n    f1: ConfidenceInterval\n    folkes_mallows_index: ConfidenceInterval\n    mcc: ConfidenceInterval\n    threat_score: ConfidenceInterval\n    markedness: ConfidenceInterval\n    fdr: ConfidenceInterval\n    npv: ConfidenceInterval\n    dor: ConfidenceInterval\n\n    def to_polars(self) -&gt; pl.DataFrame:\n        \"\"\"Transform the dataclass to a long Polars dataframe with columns\n        `metric`, `lower`, `mean`, and `upper`.\n\n        Returns\n        -------\n        pl.DataFrame\n        \"\"\"\n        dct = self.__dict__\n        lower = []\n        mean = []\n        upper = []\n        for l, m, u in dct.values():  # noqa: E741\n            lower.append(l)\n            mean.append(m)\n            upper.append(u)\n\n        return pl.DataFrame(\n            {\n                \"metric\": dct.keys(),\n                \"lower\": lower,\n                \"mean\": mean,\n                \"upper\": upper,\n            }\n        )\n</code></pre>"},{"location":"bootstrap.html#rapidstats._bootstrap.BootstrappedConfusionMatrix.to_polars","title":"<code>to_polars()</code>","text":"<p>Transform the dataclass to a long Polars dataframe with columns <code>metric</code>, <code>lower</code>, <code>mean</code>, and <code>upper</code>.</p> <p>Returns:</p> Type Description <code>DataFrame</code> Source code in <code>python/rapidstats/_bootstrap.py</code> <pre><code>def to_polars(self) -&gt; pl.DataFrame:\n    \"\"\"Transform the dataclass to a long Polars dataframe with columns\n    `metric`, `lower`, `mean`, and `upper`.\n\n    Returns\n    -------\n    pl.DataFrame\n    \"\"\"\n    dct = self.__dict__\n    lower = []\n    mean = []\n    upper = []\n    for l, m, u in dct.values():  # noqa: E741\n        lower.append(l)\n        mean.append(m)\n        upper.append(u)\n\n    return pl.DataFrame(\n        {\n            \"metric\": dct.keys(),\n            \"lower\": lower,\n            \"mean\": mean,\n            \"upper\": upper,\n        }\n    )\n</code></pre>"},{"location":"correlation.html","title":"Correlation","text":""},{"location":"correlation.html#rapidstats._corr.correlation_matrix","title":"<code>correlation_matrix(data, l1=None, l2=None, method='pearson')</code>","text":"<p>Compute the correlation matrix between two lists of columns. If both lists are None, then the correlation matrix is over all columns in the input DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[LazyFrame, DataFrame, ConvertibleToPolars]</code> <p>The input DataFrame. It must be either a Polars Frame or something convertible to a Polars Frame.</p> required <code>l1</code> <code>list[str]</code> <p>A list of columns to appear as the columns of the correlation matrix, by default None</p> <code>None</code> <code>l2</code> <code>list[str]</code> <p>A list of columns to appear as the rows of the correlation matrix, by default None</p> <code>None</code> <code>method</code> <code>CorrelationMethod</code> <p>How to calculate the correlation, by default \"pearson\"</p> <code>'pearson'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A correlation matrix with <code>l1</code> as the columns and <code>l2</code> as the rows</p> Source code in <code>python/rapidstats/_corr.py</code> <pre><code>def correlation_matrix(\n    data: Union[pl.LazyFrame, pl.DataFrame, ConvertibleToPolars],\n    l1: list[str] = None,\n    l2: list[str] = None,\n    method: CorrelationMethod = \"pearson\",\n) -&gt; pl.DataFrame:\n    \"\"\"Compute the correlation matrix between two lists of columns. If both lists are\n    None, then the correlation matrix is over all columns in the input DataFrame.\n\n    Parameters\n    ----------\n    data : Union[pl.LazyFrame, pl.DataFrame, ConvertibleToPolars]\n        The input DataFrame. It must be either a Polars Frame or something convertible\n        to a Polars Frame.\n    l1 : list[str], optional\n        A list of columns to appear as the columns of the correlation matrix,\n        by default None\n    l2 : list[str], optional\n        A list of columns to appear as the rows of the correlation matrix,\n        by default None\n    method : CorrelationMethod, optional\n        How to calculate the correlation, by default \"pearson\"\n\n    Returns\n    -------\n    pl.DataFrame\n        A correlation matrix with `l1` as the columns and `l2` as the rows\n    \"\"\"\n    pf = _to_polars(data)\n\n    if l1 is None and l2 is None:\n        original = pf.select(cs.numeric() | cs.boolean()).columns\n        new_columns = [f\"{i}\" for i, _ in enumerate(original)]\n        combinations = itertools.combinations(new_columns, r=2)\n        l1 = original[:-1]\n        l2 = original[1:]\n    else:\n        new_l1 = [f\"l{i}\" for i, _ in enumerate(l1)]\n        new_l2 = [f\"r{i}\" for i, _ in enumerate(l2)]\n        new_columns = new_l1 + new_l2\n        combinations = _pairs(new_l1, new_l2)\n        original = l1 + l2\n\n    corr_mat = (\n        pf.lazy()\n        .select(original)\n        .rename({old: new for old, new in zip(original, new_columns)})\n        .select(_corr_expr(c1, c2, method=method) for c1, c2 in combinations)\n        .melt()\n        .with_columns(pl.col(\"variable\").str.split(\"_\"))\n        .with_columns(\n            pl.col(\"variable\").list.get(0).alias(\"c1\"),\n            pl.col(\"variable\").list.get(1).alias(\"c2\"),\n        )\n        .drop(\"variable\")\n        .collect()\n        .pivot(index=\"c2\", columns=\"c1\", values=\"value\")\n        .drop(\"c2\")\n    )\n\n    corr_mat.columns = l1\n    corr_mat = corr_mat.with_columns(pl.Series(\"\", l2)).select(\"\", *l1)\n\n    return corr_mat\n</code></pre>"}]}